{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util._io import read_config\n",
    "from collections import namedtuple\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastsca\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155913, 20265)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = '/projects/experiments/fastsca/'\n",
    "server = Path.home().as_posix()\n",
    "experiment_home = server+experiment\n",
    "experiment_config = read_config(experiment_home+'config.yaml')\n",
    "args = namedtuple('Struct',experiment_config.keys())(*experiment_config.values())\n",
    "\n",
    "sca = fastsca.FASTSCA()\n",
    "sca.config = args\n",
    "sca.initdata()\n",
    "sca.loaddata()\n",
    "sca.data.mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1429, 20265)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = sca.config.home + sca.config.experiment +sca.config.output + sca.config.sample_id+'/'+sca.config.sample_id\n",
    "df = pd.read_csv(fpath+\"_rp_bulk.csv.gz\")\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare random projected data with the original data before modeling \n",
    "\n",
    "Idea from ->\n",
    "\n",
    "Efficient Generation of Transcriptomic Profiles by Random Composite Measurements\n",
    "\n",
    "Similarity of Expression Profiles: To test the method, we applied it to each dataset, comparing the pairwise distances in the original high-dimensional space X (full original dataset), with those between samples as represented in the low-dimensional embedding, Y (compressed dataset). With only m = 100 random composite measurements, the Pear- son correlation coefficient (averaged across the datasets) be- tween the distances in the low- and high-dimensional spaces was 94.4%. With m = 400 random measurements, the average correlation was 98.5%.\n",
    "\n",
    "In this case,\n",
    "$$Y_{N\\times M} = X_{N \\times G} R_{G \\times M}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.dot(sca.data.mtx,df.T.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 2700) (2700, 2700)\n",
      "0.7922996271343656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "dist = DistanceMetric.get_metric('euclidean')\n",
    "\n",
    "y_dist = dist.pairwise(y)\n",
    "x_dist = dist.pairwise(sca.data.mtx)\n",
    "print(y_dist.shape, x_dist.shape)\n",
    "\n",
    "y_dist_n = y_dist -y_dist.mean(1, keepdims=True)\n",
    "x_dist_n = x_dist -x_dist.mean(1, keepdims=True)\n",
    "\n",
    "# compute the row-wise Pearson correlation coefficients between the variables in x and y.\n",
    "corr = []\n",
    "for i in range(2700):\n",
    "    corr.append(np.corrcoef(x_dist_n[i],y_dist_n[i])[0,1])\n",
    "print(np.mean(corr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PBMC\n",
    "- when depth is 4 and dimension is 10 then average correlation is 0.71\n",
    "- when depth is 8 and dimension is 19 then average correlation is 0.68\n",
    "- when depth is 16 and dimension is 173 then average correlation is 0.77\n",
    "- when depth is 32 and dimension is 924 then average correlation is 0.79\n",
    "\n",
    "# TNBC\n",
    "\n",
    "Bulk dimension is (1429, 20265) - with min_leaf = 250, max_depth = 25\n",
    "\n",
    "also,\n",
    "Bulk dimension is (233, 20265) - with min_leaf = 1000, max_depth = 16\n",
    " - y = np.dot(sca.data.mtx,df.T.to_numpy()) \n",
    " is taking >15 mins.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('ssubedi')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:41:03) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "456174486433d0df38b6c3d43662f9cf9ff34eb8be065c50f397edd6e06d981c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
