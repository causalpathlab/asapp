sim_r_0.99_d_10000_s_7700_s_2
running asap...
source .../home/BCCRC.CA/ssubedi/projects/experiments/asapp/figures/fig_3_b/data/sim_r_0.99_d_10000_s_7700_s_2*
Dataset : sim_r_0.99_d_10000_s_7700_s_2 , cells : 100100, genes : 17204
None
Generating common genes...
Merging datasets...
processing.../home/BCCRC.CA/ssubedi/projects/experiments/asapp/figures/fig_3_b/results/sim_r_0.99_d_10000_s_7700_s_2
processing...sim_r_0.99_d_10000_s_7700_s_2
completed.
974
(974, 1762)
966
(966, 1812)
966
(966, 1810)
96
(96, 1721)
964
(964, 1769)
Filename: /home/BCCRC.CA/ssubedi/projects/experiments/asapp/figures/fig_3_b/step2_nmf.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    49    411.2 MiB    411.2 MiB           1   @profile
    50                                         def _asap(sample,data_size,wdir,n_topics,cluster_resolution):
    51                                         	
    52    466.4 MiB     55.2 MiB           1   	asappy.create_asap_data(sample,working_dirpath=wdir)
    53                                         	
    54    466.4 MiB      0.0 MiB           1   	number_batches = 1
    55    466.4 MiB      0.0 MiB           1   	asap_data_size = 25000
    56                                          
    57    466.4 MiB      0.0 MiB           1   	if data_size[0]>asap_data_size: 
    58    466.4 MiB      0.0 MiB           1   		number_batches = np.ceil(data_size[0]/asap_data_size)
    59                                           
    60    469.5 MiB      3.1 MiB           1   	asap_object = asappy.create_asap_object(sample=sample,data_size=asap_data_size,number_batches=number_batches,working_dirpath=wdir)
    61                                          
    62  10336.2 MiB   9866.6 MiB           1   	asappy.generate_pseudobulk(asap_object,tree_depth=10,normalize_pb='lscale')
    63   7649.3 MiB  -2686.9 MiB           1   	asappy.asap_nmf(asap_object,num_factors=n_topics,seed=seed)
    64                                         
    65   7657.0 MiB      7.7 MiB           1   	asap_adata = asappy.generate_model(asap_object,return_object=True)
    66                                          	
    67   8377.6 MiB    720.6 MiB           1   	asappy.leiden_cluster(asap_adata,resolution=cluster_resolution)
    68                                         
    69   8383.7 MiB      6.1 MiB           1   	ct = getct(asap_adata.obs.index.values)
    70                                         
    71   8383.7 MiB      0.0 MiB           1   	cluster = asap_adata.obs.cluster.values
    72                                         
    73   8383.7 MiB      0.0 MiB           1   	s1  = calculate_purity(ct,cluster)
    74                                         
    75   8383.7 MiB      0.0 MiB           1   	s2,s3 = calc_score(ct,cluster)
    76                                         	
    77   8383.7 MiB      0.0 MiB           1   	return s1,s2,s3


running liger....
Filename: /home/BCCRC.CA/ssubedi/projects/experiments/asapp/figures/fig_3_b/step2_nmf.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    79   8383.7 MiB   8383.7 MiB           1   @profile
    80                                         def _ligerpipeline(data_file,K,cluster_resolution):
    81                                         
    82   8383.7 MiB      0.0 MiB           1   	from sklearn.model_selection import train_test_split
    83   8386.3 MiB      2.6 MiB           1   	import pyliger
    84                                          
    85   8386.3 MiB      0.0 MiB           1   	f = hf.File(data_file,'r')
    86   8386.3 MiB      0.0 MiB           1   	data_size = tuple(f['matrix']['shape'])
    87  21525.1 MiB  13138.8 MiB           1   	mtx = csr_matrix((f['matrix']['data'], f['matrix']['indices'], f['matrix']['indptr']), shape=data_size).toarray()
    88  21527.4 MiB      1.7 MiB       17207   	var = [x.decode('utf-8') for x in list(f['matrix']['features']['id']) ]
    89  21537.4 MiB      3.0 MiB      100103   	obs = [x.decode('utf-8') for x in list(f['matrix']['barcodes']) ]
    90  21533.9 MiB     -3.5 MiB           1   	f.close()
    91                                         
    92                                         
    93  21540.1 MiB      6.2 MiB           1   	adata = an.AnnData(mtx)
    94  21540.1 MiB      0.0 MiB           1   	dfvars = pd.DataFrame(var)
    95  21540.1 MiB      0.0 MiB           1   	dfobs = pd.DataFrame(obs)
    96  21535.2 MiB     -4.9 MiB           1   	adata.obs = dfobs
    97  21534.4 MiB     -0.8 MiB           1   	adata.var = dfvars
    98  21534.4 MiB      0.0 MiB           1   	adata.var.rename(columns={0:'gene'},inplace=True) 
    99  21534.4 MiB      0.0 MiB           1   	adata.obs.rename(columns={0:'cell'},inplace=True) 
   100  21534.4 MiB      0.0 MiB           1   	adata.obs.index.name = 'cell'
   101  21534.4 MiB      0.0 MiB           1   	adata.var.index.name = 'gene'
   102                                         
   103  21534.4 MiB      0.0 MiB           1   	test_size = 0.5
   104  21534.4 MiB      0.0 MiB           1   	adata_train, adata_test = train_test_split(adata, test_size=test_size, random_state=42)
   105                                         
   106  28106.4 MiB   6572.0 MiB           1   	adata_train.uns['sample_name'] = 'train'
   107  34680.0 MiB   6573.6 MiB           1   	adata_test.uns['sample_name'] = 'test'
   108  34680.0 MiB      0.0 MiB           1   	adata_list = [adata_train,adata_test]
   109                                         
   110                                         
   111  36515.5 MiB   1835.5 MiB           1   	ifnb_liger = pyliger.create_liger(adata_list,remove_missing=False)
   112                                          
   113  38344.9 MiB   1829.4 MiB           1   	pyliger.normalize(ifnb_liger)
   114                                          
   115  25206.4 MiB -13138.4 MiB           1   	pyliger.select_genes(ifnb_liger)
   116                                         	
   117  25206.4 MiB      0.0 MiB           1   	gene_use = 2000
   118  25206.4 MiB      0.0 MiB           1   	ifnb_liger.adata_list[0].uns['var_gene_idx'] = ifnb_liger.adata_list[0].var['norm_var'].sort_values(ascending=False).index.values[:gene_use]
   119  25206.4 MiB      0.0 MiB           1   	ifnb_liger.adata_list[1].uns['var_gene_idx'] = ifnb_liger.adata_list[1].var['norm_var'].sort_values(ascending=False).index.values[:gene_use]
   120  25206.4 MiB      0.0 MiB           1   	ifnb_liger.var_genes = np.union1d(ifnb_liger.adata_list[0].uns['var_gene_idx'],ifnb_liger.adata_list[1].uns['var_gene_idx'])
   121                                           
   122  36182.0 MiB  10975.6 MiB           1   	pyliger.scale_not_center(ifnb_liger)
   123  34354.8 MiB  -1827.2 MiB           1   	pyliger.optimize_ALS(ifnb_liger, k = K,rand_seed=seed)
   124  32530.5 MiB  -1824.3 MiB           1   	pyliger.quantile_norm(ifnb_liger)
   125  32578.5 MiB     48.0 MiB           1   	pyliger.leiden_cluster(ifnb_liger,resolution=cluster_resolution)
   126                                         
   127  32578.5 MiB      0.0 MiB           1   	obs = list(ifnb_liger.adata_list[0].obs.cell.values) + list(ifnb_liger.adata_list[1].obs.cell.values)
   128  32580.1 MiB      1.5 MiB           1   	cluster = list(ifnb_liger.adata_list[0].obs.cluster.values) + list(ifnb_liger.adata_list[1].obs.cluster.values)
   129                                         	
   130  32586.3 MiB      6.2 MiB           1   	ct = getct(obs)
   131                                         
   132  32586.3 MiB      0.0 MiB           1   	s1  = calculate_purity(ct,cluster)
   133                                         
   134  32586.3 MiB      0.0 MiB           1   	s2,s3 = calc_score(ct,cluster)
   135                                         	
   136  32586.3 MiB      0.0 MiB           1   	return s1,s2,s3


